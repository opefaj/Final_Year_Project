{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "pip3 install dask[complete] toolz cloudpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"CDR_Data_IC/SET1TSV/\"\n",
    "ant_pos_loc = \"CDR_Data_IC/ANT_POS.TSV\"\n",
    "all_CDR_files = \"CDR_Data_IC/SET1TSV/*.TSV\"\n",
    "vor_path = \"CDR_Data_IC/Voronoi_Polygons/Proportions/\"\n",
    "points_in_polygon = \"CDR_Data_IC/Points_In_Polygon/\"\n",
    "\n",
    "# Retrieve required files for Cote D'Ivoire.\n",
    "complete_cdr_data = dd.read_csv(all_CDR_files, delim_whitespace=True, header=None, \n",
    "                       names=['Date', 'Time', 'Outgoing', 'Terminating', 'Num_Calls', 'Total_Duration'],\n",
    "                       usecols=['Outgoing', 'Terminating', 'Num_Calls'])\n",
    "\n",
    "antenna_positions = pd.read_csv(ant_pos_loc, delim_whitespace=True, header=None, \n",
    "                                names = [\"CT\", \"Latitude\", \"Longitude\"], index_col=\"CT\")\n",
    "\n",
    "voronoi_admin_1 = pd.read_csv(vor_path + \"voronoi_admin_1.csv\", \n",
    "                              usecols=[\"CT\", \"O_Area_km2\", \"ID_1\", \"P_Area_km2\"], index_col=\"CT\")\n",
    "\n",
    "voronoi_admin_2 = pd.read_csv(vor_path + \"voronoi_admin_2.csv\", \n",
    "                              usecols=[\"CT\", \"O_Area_km2\", \"ID_2\", \"P_Area_km2\"], index_col=\"CT\")\n",
    "\n",
    "voronoi_admin_3 = pd.read_csv(vor_path + \"voronoi_admin_3.csv\", \n",
    "                              usecols=[\"CT\", \"O_Area_km2\", \"ID_3\", \"P_Area_km2\"], index_col=\"CT\")\n",
    "\n",
    "pip_admin_1 = pd.read_csv(points_in_polygon + \"PIP_Admin_1.csv\", usecols=[\"ID_1\", \"NUMPOINTS\"], index_col=\"ID_1\")\n",
    "pip_admin_1.index.names = ['Region']\n",
    "pip_admin_1.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "pip_admin_2 = pd.read_csv(points_in_polygon + \"PIP_Admin_2.csv\", usecols=[\"ID_2\", \"NUMPOINTS\"], index_col=\"ID_2\")\n",
    "pip_admin_2.index.names = ['Region']\n",
    "pip_admin_2.sort_index(ascending=True, inplace=True)\n",
    "\n",
    "pip_admin_3 = pd.read_csv(points_in_polygon + \"PIP_Admin_3.csv\", usecols=[\"ID_3\", \"NUMPOINTS\"], index_col=\"ID_3\")\n",
    "pip_admin_3.index.names = ['Region']\n",
    "pip_admin_3.sort_index(ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findSameGeoLocatedCTs(CT_pos):\n",
    "    ids = list(CT_pos.index.unique())\n",
    "    id_series = CT_pos.index.unique()\n",
    "\n",
    "    # The CTs which have the same geo-location.\n",
    "    result = CT_pos[CT_pos.duplicated([\"Latitude\",\"Longitude\"], keep=False)].sort_values(\"Latitude\")\n",
    "    return result, ids\n",
    "\n",
    "same_geo, ids = findSameGeoLocatedCTs(antenna_positions)\n",
    "print(same_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findMissingCTs(CDR_Data):\n",
    "    present_ids = np.unique(CDR_Data[[\"Outgoing\", \"Terminating\"]].values)\n",
    "    result = set(ids) - set(present_ids)\n",
    "    return result\n",
    "\n",
    "start = time.time()\n",
    "missing_data = findMissingCTs(complete_cdr_data)\n",
    "elapsed = time.time() - start\n",
    "print(missing_data)\n",
    "print(elapsed / 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeUndirectedWeights(dataframe):\n",
    "    a = dataframe.copy()\n",
    "    b = dataframe.copy()\n",
    "\n",
    "    c = pd.merge(a, b, left_on=['Terminating','Outgoing'], right_on=['Outgoing', 'Terminating'], how='left')\n",
    "    c = c.fillna(0)\n",
    "    c['Weight'] = 0\n",
    "\n",
    "    # If outgoing != incoming then weight = call_a + call_b, else use call_a only.\n",
    "    c['Weight'] = (c['Num_Calls_x'] + c['Num_Calls_y']).where(c['Outgoing_x'] != c['Terminating_x'], c['Num_Calls_x'])\n",
    "        \n",
    "    c.drop(['Outgoing_y', 'Terminating_y'], axis=1, inplace=True)\n",
    "    c = c.rename(columns={'Outgoing_x': 'Outgoing', 'Terminating_x': 'Terminating', 'Num_Calls_x': 'Num_Calls'})\n",
    "    c.index.name = 'Index'\n",
    "    \n",
    "    return c\n",
    "    \n",
    "def preprocessCDRData(CDR_Data):\n",
    "\n",
    "    keep_columns = ['Outgoing', 'Terminating', 'Num_Calls']\n",
    "    CDR_Data = CDR_Data[keep_columns]\n",
    "    \n",
    "    # Remove any row that has an unknown CT.\n",
    "    known_outgoing = CDR_Data['Outgoing'] >= 0\n",
    "    known_terminating = CDR_Data['Terminating'] >= 0\n",
    "    CDR_Data = CDR_Data[known_outgoing & known_terminating]\n",
    "\n",
    "    # Initial Grouping to get all existing CT pairs.\n",
    "    grouped_1 = CDR_Data.groupby(by=['Outgoing', 'Terminating'])\n",
    "    \n",
    "    # Sum up Total Number of Calls per (Outgoing, Terminating) pair. \n",
    "    all_pairs = grouped_1.sum().compute()\n",
    "    all_pairs.reset_index(inplace=True)\n",
    "    all_pairs.index.names = ['Index']\n",
    "    print(\"Total number of calls between CT pairs\\n\")\n",
    "    print(all_pairs.head())\n",
    "    print()\n",
    "    \n",
    "    # Compute undirected weight of (Outgoing, Terminating) pair.\n",
    "    bidirectional = computeUndirectedWeights(all_pairs)\n",
    "    bidirectional.reset_index(inplace=True)\n",
    "    print(\"Bidirectional CT Pairs\")\n",
    "    print(bidirectional.head())\n",
    "    print()\n",
    "    \n",
    "    # Group by Outgoing CT.\n",
    "    CT_grouping = bidirectional.groupby('Outgoing')\n",
    "    \n",
    "    # Total Activity for each CT.     \n",
    "    total_activity = CT_grouping.sum()\n",
    "    total_activity.reset_index(inplace=True)\n",
    "    total_activity.set_index('Outgoing', inplace=True)\n",
    "    total_activity= total_activity.rename(columns={'Weight': 'Total_Weight'}) \n",
    "    keep_columns=['Total_Weight']\n",
    "    total_activity =  total_activity[keep_columns]\n",
    "    \n",
    "    print(\"CTs with total activity\")\n",
    "    print(total_activity.head())\n",
    "    print()\n",
    "    \n",
    "    return bidirectional, CT_grouping, total_activity\n",
    "    \n",
    "\n",
    "start = time.time()\n",
    "bidirectional_CT, CT_groups, total_CT_activity = preprocessCDRData(complete_cdr_data)\n",
    "elapsed = time.time() - start\n",
    "print(elapsed / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# METRIC 1: Activity.\n",
    "\n",
    "def computeActivity(voronoi_data, CT_activity, region_name, scale):\n",
    "    regional_activity = pd.DataFrame(columns=['Region', 'Activity'])\n",
    "    regional_activity['Region'] = list(voronoi_data[region_name].unique())\n",
    "    regional_activity.set_index('Region', inplace=True)\n",
    "    regional_activity['Activity'] = 0\n",
    "    regional_activity.sort_index(ascending=True, inplace=True)\n",
    "    \n",
    "    indices = CT_activity.index\n",
    "    \n",
    "    for index, row in voronoi_data.iterrows():\n",
    "        ct = index\n",
    "        region = row[region_name]\n",
    "        \n",
    "        if(row['O_Area_km2'] == 0):\n",
    "            continue\n",
    "        proportion = row['P_Area_km2'] / row['O_Area_km2']\n",
    "        \n",
    "        # Proportion = nan sometimes because original area = 0.\n",
    "        if(math.isnan(proportion)):\n",
    "            continue\n",
    "\n",
    "        if(ct in indices):\n",
    "            prev_value = regional_activity.loc[region, 'Activity']\n",
    "            ct_weight = CT_activity.loc[ct, 'Total_Weight'] * scale\n",
    "            regional_activity.loc[region, 'Activity'] = (proportion * ct_weight) + prev_value\n",
    "    \n",
    "    return regional_activity\n",
    "\n",
    "regional_activity_1 = computeActivity(voronoi_admin_1, total_CT_activity, \"ID_1\", 1)\n",
    "regional_activity_2 = computeActivity(voronoi_admin_2, total_CT_activity, \"ID_2\", 1)\n",
    "regional_activity_3 = computeActivity(voronoi_admin_3, total_CT_activity, \"ID_3\", 1)\n",
    "\n",
    "print(regional_activity_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC 3: Network Advantage.\n",
    "\n",
    "def extractKMedian(ct_activity, grouping):\n",
    "    ct_activity['kmedian'] = 0\n",
    "    ct_activity['k_degree'] = 0\n",
    "    ct_activity['k_sum'] = 0\n",
    "    \n",
    "    for name, group in grouping:\n",
    "        weights = sorted(list(group['Weight']))\n",
    "        \n",
    "        mid = int(len(weights) / 2)\n",
    "        k_mid = weights[mid]\n",
    "        ct_activity.loc[name, 'kmedian'] = k_mid\n",
    "        \n",
    "        k_deg = sum(1 for _ in weights if _ > k_mid)\n",
    "        ct_activity.loc[name, 'k_degree'] = k_deg\n",
    "        \n",
    "        k_sum = sum(x for x in weights if x > k_mid)\n",
    "        ct_activity.loc[name, 'k_sum'] = k_sum\n",
    "        \n",
    "def computeNormalisedEntropy(ct_activity, grouping, ct_pairs, voronoi_data, region_data, region_name):\n",
    "    \n",
    "    # Merge CT total activity with pairs to give CT totals & K Medians for purpose of calculating the fractions.    \n",
    "    merged = pd.merge(ct_pairs, ct_activity, left_on = 'Outgoing', right_index=True)\n",
    "    keep_columns = ['Index', 'Outgoing', 'Terminating', 'Weight', 'Total_Weight']\n",
    "    merged =  merged[keep_columns]\n",
    "    merged.set_index('Index', inplace=True)\n",
    "    \n",
    "    # Calculate fraction * log(fraction) per CT pair.     \n",
    "    fraction = merged['Weight'] / merged['Total_Weight']\n",
    "    natural_log_fraction = np.log(fraction)\n",
    "    merged['Fraction_Product'] = fraction * natural_log_fraction\n",
    "\n",
    "    print(\"Merged CT_pairs & Total_Activity\")\n",
    "    print(merged.head())\n",
    "    print()\n",
    "    \n",
    "    # Get total of fraction * log(fraction) for each CT. [CT, Sum_Fraction_Product].   \n",
    "    sum_fraction_product = merged.groupby('Outgoing').sum()\n",
    "    keep_columns = ['Fraction_Product']\n",
    "    sum_fraction_product = sum_fraction_product[keep_columns]\n",
    "    print(sum_fraction_product.head())\n",
    "    print()\n",
    "    \n",
    "    # Merge ct_activity with fraction_product. Add entropy column = sum_fraction_product / log(k_degree).  \n",
    "    ct_activity = pd.merge(ct_activity, sum_fraction_product, how='left', left_index=True, right_index=True)\n",
    "    ct_activity['ct_entropy'] = (-1 * (ct_activity['Fraction_Product']) / np.log(ct_activity['k_degree']))\n",
    "    print(ct_activity.head())\n",
    "    print()\n",
    "    \n",
    "    indices = ct_activity.index\n",
    "    \n",
    "    region_entropy = region_data.copy()\n",
    "    region_entropy['entropy'] = 0\n",
    "    \n",
    "    for index, row in voronoi_data.iterrows():\n",
    "        ct = index\n",
    "        region = row[region_name]\n",
    "        \n",
    "        if(row['O_Area_km2'] == 0):\n",
    "            continue\n",
    "            \n",
    "        proportion = row['P_Area_km2'] / row['O_Area_km2']\n",
    "        \n",
    "        # Proportion = nan sometimes because original area = 0. An approximation as actual value is very small.\n",
    "        if(math.isnan(proportion)):\n",
    "            continue\n",
    "\n",
    "        if(ct in indices):\n",
    "            prev_value = region_entropy.loc[region, 'entropy']\n",
    "            new_value = ct_activity.loc[ct, 'ct_entropy']\n",
    "            region_entropy.loc[region, 'entropy'] = (proportion * new_value) + prev_value\n",
    "    \n",
    "    # Normalise entropy by the number of CTs in the region.\n",
    "    region_entropy['normalised_entropy'] = region_entropy['entropy'] / region_entropy['NUMPOINTS']\n",
    "    return region_entropy\n",
    "\n",
    "def computeMedianDegree(ct_activity, ct_pairs, voronoi_data, region_data, region_name, scale):\n",
    "    total_activity = ct_activity.copy()\n",
    "    \n",
    "    keep_columns = ['k_sum']\n",
    "    total_activity = total_activity[keep_columns]\n",
    "    total_activity.rename(columns={'k_sum' : 'Total_Weight'}, inplace=True)\n",
    "    \n",
    "    print(total_activity.head())\n",
    "    regional_activity = computeActivity(voronoi_data, total_activity, region_name, scale)\n",
    "    print(regional_activity.head())\n",
    "    \n",
    "    regional_activity = pd.merge(regional_activity, region_data, left_index=True, right_index=True)\n",
    "    regional_activity['medDegree'] = regional_activity['Activity'] / regional_activity['NUMPOINTS']\n",
    "    print(regional_activity)\n",
    "    keep_columns = ['medDegree']\n",
    "    regional_activity = regional_activity[keep_columns]\n",
    "    \n",
    "    return regional_activity\n",
    "\n",
    "extractKMedian(total_CT_activity, CT_groups)\n",
    "\n",
    "# Normalised Entropy\n",
    "norm_entropy_1 = computeNormalisedEntropy(total_CT_activity, CT_groups, bidirectional_CT, \n",
    "                                          voronoi_admin_1, pip_admin_1, \"ID_1\")\n",
    "\n",
    "norm_entropy_2 = computeNormalisedEntropy(total_CT_activity, CT_groups, bidirectional_CT, \n",
    "                                          voronoi_admin_2, pip_admin_2, \"ID_2\")\n",
    "\n",
    "norm_entropy_3 = computeNormalisedEntropy(total_CT_activity, CT_groups, bidirectional_CT, \n",
    "                                          voronoi_admin_3, pip_admin_3, \"ID_3\")\n",
    "\n",
    "# Median Degree.\n",
    "medDegree_1 = computeMedianDegree(total_CT_activity, bidirectional_CT, voronoi_admin_1, pip_admin_1, \"ID_1\", 1)\n",
    "medDegree_2 = computeMedianDegree(total_CT_activity, bidirectional_CT, voronoi_admin_2, pip_admin_2, \"ID_2\", 1)\n",
    "medDegree_3 = computeMedianDegree(total_CT_activity, bidirectional_CT, voronoi_admin_3, pip_admin_3, \"ID_3\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Weight  Inner_Traffic  Outer_Traffic  Introversion\n",
      "Outgoing                                                       \n",
      "1          707770.0        90981.0       616789.0      0.147507\n",
      "2          159785.0        11706.0       148079.0      0.079052\n",
      "3          174330.0        18274.0       156056.0      0.117099\n",
      "4          238144.0        16061.0       222083.0      0.072320\n",
      "5         3084195.0       368007.0      2716188.0      0.135487\n",
      "        NUMPOINTS  Introversion  avg_introversion\n",
      "Region                                           \n",
      "1              42      9.321934          0.221951\n",
      "2               9      3.097162          0.344129\n",
      "3             106     28.715430          0.270900\n",
      "4              12      3.490770          0.290897\n",
      "5              34      7.840913          0.230615\n",
      "6              44      9.121727          0.207312\n",
      "7              68     14.807226          0.217753\n",
      "8              56      7.953796          0.142032\n",
      "9             463     33.413921          0.072168\n",
      "10             37      8.759952          0.236755\n",
      "11             27      7.228996          0.267741\n",
      "12             35      9.545420          0.272726\n",
      "13             50     10.808498          0.216170\n",
      "14             46     16.059832          0.349127\n",
      "15             45     11.304036          0.251201\n",
      "16             39     11.861489          0.304141\n",
      "17             49      9.242423          0.188621\n",
      "18             24      7.481932          0.311747\n",
      "19             36      9.814662          0.272630\n",
      "0.03752686580022176\n"
     ]
    }
   ],
   "source": [
    "# METRIC 4: Introversion.\n",
    "\n",
    "def computeIntroversion(ct_activity, ct_pairs, voronoi_data, region_data, region_name):\n",
    "    ct_data = ct_pairs.copy()\n",
    "    \n",
    "    keep_columns = ['Outgoing', 'Terminating', 'Weight']\n",
    "    ct_data = ct_data[keep_columns]\n",
    "    ct_data['Inner_Traffic'] = (ct_data['Weight']).where(ct_data['Outgoing'] == ct_data['Terminating'], 0)\n",
    "    \n",
    "    ct_data = ct_data.groupby('Outgoing').sum()\n",
    "    keep_columns = ['Weight', 'Inner_Traffic']\n",
    "    ct_data = ct_data[keep_columns]\n",
    "    \n",
    "    ct_data['Outer_Traffic'] = ct_data['Weight'] - ct_data['Inner_Traffic']\n",
    "    ct_data['Introversion'] = ct_data['Inner_Traffic'] / ct_data['Outer_Traffic']\n",
    "    \n",
    "    print(ct_data.head())\n",
    "    \n",
    "    indices = ct_activity.index\n",
    "    \n",
    "    region_introversion = region_data.copy()\n",
    "    region_introversion['Introversion'] = 0\n",
    "    \n",
    "    for index, row in voronoi_data.iterrows():\n",
    "        ct = index\n",
    "        region = row[region_name]\n",
    "        \n",
    "        if(row['O_Area_km2'] == 0):\n",
    "            continue\n",
    "            \n",
    "        proportion = row['P_Area_km2'] / row['O_Area_km2']\n",
    "        \n",
    "        # Proportion = nan sometimes because original area = 0. An approximation as actual value is very small.\n",
    "        if(math.isnan(proportion)):\n",
    "            continue\n",
    "\n",
    "        if(ct in indices):\n",
    "            prev_value = region_introversion.loc[region, 'Introversion']\n",
    "            new_value = ct_data.loc[ct, 'Introversion']\n",
    "            region_introversion.loc[region, 'Introversion'] = (proportion * new_value) + prev_value\n",
    "    \n",
    "    region_introversion['avg_introversion'] = region_introversion['Introversion'] / region_introversion['NUMPOINTS']\n",
    "    return region_introversion\n",
    "    \n",
    "\n",
    "start = time.time()\n",
    "\n",
    "introversion_1 = computeIntroversion(total_CT_activity, bidirectional_CT, voronoi_admin_1, pip_admin_1, \"ID_1\")\n",
    "introversion_2 = computeIntroversion(total_CT_activity, bidirectional_CT, voronoi_admin_2, pip_admin_2, \"ID_2\")\n",
    "introversion_3 = computeIntroversion(total_CT_activity, bidirectional_CT, voronoi_admin_3, pip_admin_3, \"ID_3\")\n",
    "\n",
    "print(introversion_1)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(elapsed / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# METRIC 2.\n",
    "def calculate_distance(lat_a, long_a, lat_b, long_b):\n",
    "    earth_radius_km = 6371.0\n",
    "    \n",
    "    lat1 = radians(lat_a)\n",
    "    lon1 = radians(long_a)\n",
    "    lat2 = radians(lat_b)\n",
    "    lon2 = radians(long_b)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "    c = 2 * math.atan2(sqrt(a), math.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "    print(\"Result:\", distance)\n",
    "    return distance\n",
    "\n",
    "# function to calculate the population of each CT voronoi.\n",
    "\n",
    "# gravity residual: population in each CT voronoi, calculate distances between each pair\n",
    "def computeGravityResidual(CT_pairs, outgoing_CTs, terminating_CTs, voronoi_data):\n",
    "    #     create a data frame containing each pair and the distance and pop_a * pop_b and flow estimate, actual & diff\n",
    "    #     I need the total activity of each pair - get it from complete_outgoing & terminating\n",
    "    #     Remember I need to plot, so will need another function.\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
