{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the number of relevant responses and assigns to each region.\n",
    "def compute_simple_wha_aggregate(region_name, col_name, data):\n",
    "    admin_data = pd.DataFrame(columns=[region_name, 'Zero_Care_Row_Count', 'Zero_Care_SW_Count',\n",
    "                                       'Care_SW_Count', 'Care_Row_Count'])\n",
    "    \n",
    "    admin_data[region_name] = list(data[col_name].unique())\n",
    "    \n",
    "    # Set index to region numbers.   \n",
    "    wha_data = data.copy()\n",
    "    wha_data.set_index(col_name, inplace=True)\n",
    "    wha_data['M14$1'] = pd.to_numeric(wha_data['M14$1'], errors='coerce').fillna(-1).astype(int)\n",
    "    \n",
    "    # Set index to region numbers and sort index.\n",
    "    admin_data.set_index(region_name, inplace=True)\n",
    "    admin_data.fillna(0, inplace=True)\n",
    "    admin_data.sort_index(ascending=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    for index, row in wha_data.iterrows():\n",
    "        result = row['M14$1']\n",
    "        sample_weight = row['V005'] / 1000000\n",
    "        \n",
    "       #  Use the sample weights to summate the total number of antenatal care visits. Ignore missing values i.e. -1\n",
    "        if(result > 0 and result < 98):\n",
    "            prev = admin_data.loc[index, 'Care_SW_Count'] \n",
    "            admin_data.loc[index, 'Care_SW_Count'] = prev + (sample_weight * result)\n",
    "            \n",
    "            prev = admin_data.loc[index, 'Care_Row_Count']\n",
    "            admin_data.loc[index, 'Care_Row_Count'] = prev + result\n",
    "            \n",
    "        #  Increment the number of participants who have not had any antenatal care.\n",
    "        if(result == 0):\n",
    "            prev = admin_data.loc[index, 'Zero_Care_Row_Count']\n",
    "            admin_data.loc[index, 'Zero_Care_Row_Count'] = prev + 1\n",
    "            \n",
    "            prev = admin_data.loc[index, 'Zero_Care_SW_Count']\n",
    "            admin_data.loc[index, 'Zero_Care_SW_Count'] = prev + sample_weight\n",
    "         \n",
    "    return admin_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigns each region total number of positive responses which have been normalised by the population of the clusters.\n",
    "def wha_voronoi_aggregate(region_name, col_name, wha_recode, voronoi_data, population):\n",
    "    pop_data = population.copy()\n",
    "    vor_data = voronoi_data.copy() \n",
    "    wha_data = wha_recode.copy()\n",
    "\n",
    "    # Replace cells of no responses with -1.     \n",
    "    wha_data.set_index('V001', inplace=True)\n",
    "    wha_data['M14$1'] = pd.to_numeric(wha_data['M14$1'], errors='coerce').fillna(-1).astype(int)\n",
    "\n",
    "    # Contains aggregate for each cluster. \n",
    "    cluster_data = pd.DataFrame(columns=['V001','No_Care_Count_Aggregate','No_Care_SW_Aggregate',\n",
    "                                        'Care_Count_Aggregate', 'Care_SW_Aggregate'])\n",
    "    \n",
    "    cluster_data['V001'] = list(wha_recode['V001'].unique())\n",
    "\n",
    "    cluster_data.set_index('V001', inplace=True)\n",
    "    cluster_data.fillna(0, inplace=True)\n",
    "    cluster_data.sort_index(ascending=True, inplace=True)\n",
    "    \n",
    "    # Contains Admin Region and the women's access to health aggregates.\n",
    "    admin_region_data = pd.DataFrame(columns=[region_name, 'Care_Row_Count', 'Care_SW_Count', 'Care_Pop_Count',\n",
    "                                             'Zero_Row_Count', 'Zero_SW_Count','Zero_Pop_Count', 'Population'])\n",
    "    admin_region_data[region_name] = list(voronoi_data[col_name].unique())\n",
    "    admin_region_data.set_index(region_name, inplace=True)\n",
    "    admin_region_data.fillna(0, inplace=True)\n",
    "    admin_region_data.sort_index(ascending=True, inplace=True)\n",
    "    \n",
    "    for index, row in wha_data.iterrows():\n",
    "        value = row['M14$1']\n",
    "        sample_weight = row['V005'] / 1000000\n",
    "        \n",
    "        if(value > 0 and value < 98):\n",
    "            prev = cluster_data.loc[index, 'Care_SW_Aggregate']\n",
    "            cluster_data.loc[index, 'Care_SW_Aggregate'] = prev + (sample_weight * value)\n",
    "            \n",
    "            prev = cluster_data.loc[index, 'Care_Count_Aggregate']\n",
    "            cluster_data.loc[index, 'Care_Count_Aggregate'] = prev + value\n",
    "        \n",
    "        if(value == 0):\n",
    "            prev = cluster_data.loc[index, 'No_Care_Count_Aggregate']\n",
    "            cluster_data.loc[index,'No_Care_Count_Aggregate' ] = prev + 1\n",
    "            \n",
    "            prev = cluster_data.loc[index,'No_Care_SW_Aggregate']\n",
    "            cluster_data.loc[index, 'No_Care_SW_Aggregate'] = prev + sample_weight\n",
    "            \n",
    "            \n",
    "    cluster_data.reset_index(inplace=True)\n",
    "    \n",
    "    # Result of vor data is (cluster, region, proportion, SW_aggregate, Row_Aggregate, ..., ...).\n",
    "    vor_data = pd.merge(voronoi_data, cluster_data, how='inner', on='V001')\n",
    "    vor_data = pd.merge(vor_data, pop_data, how='inner', on='V001')\n",
    "    vor_data.reset_index(inplace=True)\n",
    "    vor_data.set_index(col_name, inplace=True)\n",
    "    vor_data.sort_index(ascending=True, inplace=True)\n",
    "    \n",
    "    # Assigns responses to regions based on voronoi overlap with region. Proportions cluster population in same way. \n",
    "    for ind, row in vor_data.iterrows():\n",
    "        care_count_prop = row['Proportion'] * row['Care_Count_Aggregate']\n",
    "        prev = admin_region_data.loc[ind,'Care_Row_Count']\n",
    "        admin_region_data.loc[ind, 'Care_Row_Count'] = prev + care_count_prop\n",
    "        \n",
    "        care_sw_prop = row['Proportion'] * row['Care_SW_Aggregate']\n",
    "        prev = admin_region_data.loc[ind, 'Care_SW_Count']\n",
    "        admin_region_data.loc[ind, 'Care_SW_Count'] = prev + care_sw_prop\n",
    "        \n",
    "        zero_count_prop = row['Proportion'] * row['No_Care_Count_Aggregate']\n",
    "        prev = admin_region_data.loc[ind,'Zero_Row_Count']\n",
    "        admin_region_data.loc[ind, 'Zero_Row_Count'] = prev + zero_count_prop\n",
    "        \n",
    "        zero_sw_prop = row['Proportion'] * row['No_Care_SW_Aggregate']\n",
    "        prev = admin_region_data.loc[ind, 'Zero_SW_Count']\n",
    "        admin_region_data.loc[ind, 'Zero_SW_Count'] = prev + zero_sw_prop \n",
    "        \n",
    "        prop = row['Proportion'] * row['Population']\n",
    "        prev = admin_region_data.loc[ind, 'Population']\n",
    "        admin_region_data.loc[ind, 'Population'] = prev + prop \n",
    "    \n",
    "    #  Normalises total responses in region using population of all clusters in the region.\n",
    "    for ind, row in admin_region_data.iterrows():\n",
    "        value = row['Zero_Row_Count'] /  row['Population']\n",
    "        admin_region_data.loc[ind, 'Zero_Pop_Count'] = value * (10**6)\n",
    "        \n",
    "        value = row['Care_Row_Count'] /  row['Population']\n",
    "        admin_region_data.loc[ind, 'Care_Pop_Count'] = value * (10**6)\n",
    "    return admin_region_data   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------HOW TO AGGREGATE-----------------\n",
      "-----NUMBER OF ANTENATAL VISITS-------\n",
      "Admin 1 - (Visits row count VOR, Visits count PIP): 0.9064327485380117\n",
      "Admin 2 - (Visits row count VOR, Visits count PIP): 0.80147085571754906\n",
      "\n",
      "----NUMBER OF ZER0 ANTENATAL VISITS-----\n",
      "Admin 1 - (Zero Care row count VOR, Zero Care count PIP): 0.92354539019687687\n",
      "Admin 2 - (Zero Care row count VOR, Zero Care count PIP): 0.86106102394459927\n",
      "\n",
      "------------------HOW TO COUNT-------------------\n",
      "------NUMBER OF ANTENATAL VISITS-------\n",
      "Admin 1 - (Visits row count VOR, Visits Sample Weight VOR): 0.48538011695906425\n",
      "Admin 1 - (Visits row count VOR, Visits pop VOR): 0.391812865497076\n",
      "\n",
      "Admin 2 - (Visits row count VOR, Visits Sample Weight VOR): 0.48244897959183675\n",
      "Admin 2 - (Visits row count VOR, Visits pop VOR): 0.29959183673469386\n",
      "\n",
      "Admin 3 - (Visits row count VOR, Visits Sample Weight VOR): 0.59964747356051706\n",
      "Admin 3 - (Visits row count VOR, Visits pop VOR): 0.45757931844888367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------COTE D'IVOIRE COMPUTATIONS--------------------------\n",
    "folder_path = \"IC_DHS/\"\n",
    "recode_path = folder_path + \"ciir62sv/\"\n",
    "path_to_voronoi = folder_path + \"Voronoi_clusters/Proportions/\"\n",
    "path_to_clusters = folder_path + \"CLUSTER_TO_REGION/\"\n",
    "\n",
    "# Population of all DHS clusters.\n",
    "population_file = pd.read_csv(folder_path + \"Region_Population/voronoi.csv\")\n",
    "population_file = population_file.rename(columns = {'DHSCLUST':'V001'})\n",
    "population_file = population_file.rename(columns = {'_count':'Population'})\n",
    "\n",
    "file = pd.read_csv(recode_path + \"individual_Recode.csv\", usecols=['V001','V002','V005','M14$1'])\n",
    "\n",
    "clust_admin = pd.read_csv(path_to_clusters + \"admin_3.csv\", usecols=['DHSCLUST', 'ID_1', 'ID_2', 'ID_3'])\n",
    "clust_admin = clust_admin.rename(columns = {'DHSCLUST':'V001'})\n",
    "\n",
    "# Voronoi Polygon & Admin Region Mapping.\n",
    "voronoi_admin_1 = pd.read_csv(path_to_voronoi + \"voronoi_admin_1.csv\")\n",
    "voronoi_admin_2 = pd.read_csv(path_to_voronoi + \"voronoi_admin_2.csv\")\n",
    "voronoi_admin_3 = pd.read_csv(path_to_voronoi + \"voronoi_admin_3.csv\")\n",
    "\n",
    "voronoi_admin_1 = voronoi_admin_1.rename(columns = {'DHSCLUST':'V001'})\n",
    "voronoi_admin_2 = voronoi_admin_2.rename(columns = {'DHSCLUST':'V001'})\n",
    "voronoi_admin_3 = voronoi_admin_3.rename(columns = {'DHSCLUST':'V001'})\n",
    "\n",
    "# Join the dataframes. \n",
    "clust_file = pd.merge(file, clust_admin, how='inner', on='V001')\n",
    "\n",
    "# ---------------------------SIMPLE AGGREGATES USING POINT IN POLYGON-------------------------------------\n",
    "admin_1 = compute_simple_wha_aggregate(\"Admin_1_Region\", \"ID_1\", clust_file)\n",
    "admin_2 = compute_simple_wha_aggregate(\"Admin_2_Region\", \"ID_2\", clust_file)\n",
    "admin_3 = compute_simple_wha_aggregate(\"Admin_3_Region\", \"ID_3\", clust_file)\n",
    "admin_1.to_csv(recode_path + \"wha_aggregate_1.csv\", index=True)\n",
    "admin_2.to_csv(recode_path + \"wha_aggregate_2.csv\", index=True)\n",
    "admin_3.to_csv(recode_path + \"wha_aggregate_3.csv\", index=True)\n",
    "\n",
    "# ---------------------------AGGREGATES USING VORONOI CALCULATIONS-------------------------------------\n",
    "admin_vor_1 = wha_voronoi_aggregate(\"Admin_Region_1\", \"ID_1\", clust_file, voronoi_admin_1, population_file)\n",
    "admin_vor_2 = wha_voronoi_aggregate(\"Admin_Region_2\", \"ID_2\", clust_file, voronoi_admin_2, population_file)\n",
    "admin_vor_3 = wha_voronoi_aggregate(\"Admin_Region_3\", \"ID_3\", clust_file, voronoi_admin_3, population_file)\n",
    "\n",
    "print(\"---------------------HOW TO AGGREGATE-----------------\")\n",
    "print(\"-----NUMBER OF ANTENATAL VISITS-------\")\n",
    "x, y = stats.kendalltau(admin_vor_1['Care_Row_Count'], admin_1['Care_Row_Count'])\n",
    "print(\"Admin 1 - (Visits row count VOR, Visits count PIP): \" +  repr(x))\n",
    "\n",
    "x, y = stats.kendalltau(admin_vor_2['Care_Row_Count'], admin_2['Care_Row_Count'])\n",
    "print(\"Admin 2 - (Visits row count VOR, Visits count PIP): \" +  repr(x) + \"\\n\")\n",
    "\n",
    "print(\"----NUMBER OF ZER0 ANTENATAL VISITS-----\")\n",
    "x, y = stats.kendalltau(admin_vor_1['Zero_Row_Count'], admin_1['Zero_Care_Row_Count'])\n",
    "print(\"Admin 1 - (Zero Care row count VOR, Zero Care count PIP): \" +  repr(x))\n",
    "\n",
    "x, y = stats.kendalltau(admin_vor_2['Zero_Row_Count'], admin_2['Zero_Care_Row_Count'])\n",
    "print(\"Admin 2 - (Zero Care row count VOR, Zero Care count PIP): \" +  repr(x) + \"\\n\")\n",
    "\n",
    "print(\"------------------HOW TO COUNT-------------------\")\n",
    "print(\"------NUMBER OF ANTENATAL VISITS-------\")\n",
    "x, y = stats.kendalltau(admin_vor_1['Care_Row_Count'], admin_vor_1['Care_SW_Count'])\n",
    "print(\"Admin 1 - (Visits row count VOR, Visits Sample Weight VOR): \" + repr(x))\n",
    "\n",
    "x, y = stats.kendalltau(admin_vor_1['Care_Row_Count'], admin_vor_1['Care_Pop_Count'])\n",
    "print(\"Admin 1 - (Visits row count VOR, Visits pop VOR): \" + repr(x) + \"\\n\")\n",
    "\n",
    "x, y = stats.kendalltau(admin_vor_2['Care_Row_Count'], admin_vor_2['Care_SW_Count'])\n",
    "print(\"Admin 2 - (Visits row count VOR, Visits Sample Weight VOR): \" + repr(x))\n",
    "\n",
    "x, y = stats.kendalltau(admin_vor_2['Care_Row_Count'], admin_vor_2['Care_Pop_Count'])\n",
    "print(\"Admin 2 - (Visits row count VOR, Visits pop VOR): \" + repr(x) + \"\\n\")\n",
    "\n",
    "x, y = stats.kendalltau(admin_vor_3['Care_Row_Count'], admin_vor_3['Care_SW_Count'])\n",
    "print(\"Admin 3 - (Visits row count VOR, Visits Sample Weight VOR): \" + repr(x))\n",
    "\n",
    "x, y = stats.kendalltau(admin_vor_3['Care_Row_Count'], admin_vor_3['Care_Pop_Count'])\n",
    "print(\"Admin 3 - (Visits row count VOR, Visits pop VOR): \" + repr(x) + \"\\n\")\n",
    "\n",
    "admin_vor_1.to_csv(recode_path + \"wha_vor_aggregate_1.csv\", index=True)\n",
    "admin_vor_2.to_csv(recode_path + \"wha_vor_aggregate_2.csv\", index=True)\n",
    "admin_vor_3.to_csv(recode_path + \"wha_vor_aggregate_3.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  ------------------------------------SENEGAL COMPUTATIONS--------------------------------------------------\n",
    "folder_path = \"SEN_DHS/\"\n",
    "recode_path = folder_path + \"SNIR6DSV/\"\n",
    "path_to_voronoi = folder_path + \"Voronoi/Proportions/\"\n",
    "path_to_clusters = folder_path + \"Cluster_To_Region/\"\n",
    "\n",
    "# Population of all DHS clusters.\n",
    "population_file = pd.read_csv(folder_path + \"Region_Populations/voronoi_pop.csv\")\n",
    "population_file = population_file.rename(columns = {'DHSCLUST':'V001'})\n",
    "population_file = population_file.rename(columns = {'_count':'Population'})\n",
    "\n",
    "file = pd.read_csv(recode_path + \"individual_recode.csv\", usecols=['V001','V002','V005','M14$1'])\n",
    "\n",
    "clust_admin = pd.read_csv(path_to_clusters + \"admin_3.csv\", usecols=['DHSCLUST', 'ID_1', 'ID_2', 'ID_3'])\n",
    "clust_admin = clust_admin.rename(columns = {'DHSCLUST':'V001'})\n",
    "\n",
    "# Voronoi Polygon & Admin Region Mapping.\n",
    "voronoi_admin_1 = pd.read_csv(path_to_voronoi + \"voronoi_admin_1.csv\")\n",
    "voronoi_admin_2 = pd.read_csv(path_to_voronoi + \"voronoi_admin_2.csv\")\n",
    "voronoi_admin_3 = pd.read_csv(path_to_voronoi + \"voronoi_admin_3.csv\")\n",
    "\n",
    "voronoi_admin_1 = voronoi_admin_1.rename(columns = {'DHSCLUST':'V001'})\n",
    "voronoi_admin_2 = voronoi_admin_2.rename(columns = {'DHSCLUST':'V001'})\n",
    "voronoi_admin_3 = voronoi_admin_3.rename(columns = {'DHSCLUST':'V001'})\n",
    "\n",
    "clust_file = pd.merge(file, clust_admin, how='inner', on='V001')\n",
    "\n",
    "#  Set empty cells to -1.   \n",
    "clust_file['M14$1'] = pd.to_numeric(clust_file['M14$1'], errors='coerce').fillna(-1).astype(int)\n",
    "clust_file.to_csv(recode_path + \"complete_health_access_data.csv\", index=False)\n",
    "\n",
    "admin_vor_1 = wha_voronoi_aggregate(\"Admin_Region_1\", \"ID_1\", clust_file, voronoi_admin_1, population_file)\n",
    "admin_vor_2 = wha_voronoi_aggregate(\"Admin_Region_2\", \"ID_2\", clust_file, voronoi_admin_2, population_file)\n",
    "admin_vor_3 = wha_voronoi_aggregate(\"Admin_Region_3\", \"ID_3\", clust_file, voronoi_admin_3, population_file)\n",
    "\n",
    "admin_vor_1.to_csv(recode_path + \"wha_vor_aggregate_1.csv\", index=True)\n",
    "admin_vor_2.to_csv(recode_path + \"wha_vor_aggregate_2.csv\", index=True)\n",
    "admin_vor_3.to_csv(recode_path + \"wha_vor_aggregate_3.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
